{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 7 del curso CM-072\n",
    "\n",
    "* Nombre y apellidos: Kevin Daniel Molina Bejar\n",
    "* Fecha de presentación: 17 de octubre.\n",
    "\n",
    "\n",
    "\n",
    "LendingClub es una compañía de préstamos *peer-to-peer* que conecta directamente a los prestatarios con potenciales prestamistas/inversionistas.\n",
    "\n",
    "Construirás un modelo de clasificación para predecir si un préstamo realizado a través del LendingClub tiene probabilidad de no ser pagado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "loans = pd.read_csv(\"lending-club-data.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 . Carga en una variable de nombre `todo_columnas` el nombre de todas las columnas del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'member_id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv',\n",
      "       'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_title',\n",
      "       'emp_length', 'home_ownership', 'annual_inc', 'is_inc_v', 'issue_d',\n",
      "       'loan_status', 'pymnt_plan', 'url', 'desc', 'purpose', 'title',\n",
      "       'zip_code', 'addr_state', 'dti', 'delinq_2yrs', 'earliest_cr_line',\n",
      "       'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record',\n",
      "       'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc',\n",
      "       'initial_list_status', 'out_prncp', 'out_prncp_inv', 'total_pymnt',\n",
      "       'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int',\n",
      "       'total_rec_late_fee', 'recoveries', 'collection_recovery_fee',\n",
      "       'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d', 'last_credit_pull_d',\n",
      "       'collections_12_mths_ex_med', 'mths_since_last_major_derog',\n",
      "       'policy_code', 'not_compliant', 'status', 'inactive_loans', 'bad_loans',\n",
      "       'emp_length_num', 'grade_num', 'sub_grade_num', 'delinq_2yrs_zero',\n",
      "       'pub_rec_zero', 'collections_12_mths_zero', 'short_emp',\n",
      "       'payment_inc_ratio', 'final_d', 'last_delinq_none', 'last_record_none',\n",
      "       'last_major_derog_none'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Solucion\n",
    "todo_columnas= loans.columns\n",
    "print(todo_columnas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 . La columna que contiene la información que queremos predecir se llama `malos_prestamos`. En esta columna, el valor 1 significa un préstamo riesgoso (malo), mientras que 0 significa un préstamos seguro.\n",
    "\n",
    "Para hacer el trabajo más intuitivo, crea una nueva columna `prestamos_seguros` con el siguiente valor:\n",
    "\n",
    "* +1 si es un préstamo seguro\n",
    "* -1 si es un préstamos riesgoso (malo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solucion\n",
    "loans['prestamos_seguros']=-1\n",
    "loans.prestamos_seguros[loans.bad_loans==0]=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 . Calcula la distribución en porcentaje de préstamos malos y préstamos buenos (debe sumar 100%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    0.811185\n",
       "-1    0.188815\n",
       "Name: prestamos_seguros, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tu solución\n",
    "loans.prestamos_seguros.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 . Una manera de abordar conjuntos de datos desbalanceados es con un submuestreo  de la clase más grande hasta que la distribución de clases sea mitad y mitad. Vamos a realizar un submuestreo de los préstamos buenos para balancear nuestro conjunto de datos. Ello significa que vamos a descartar muchas observaciones. \n",
    "\n",
    "* Pon en una variable `prestamos_arriesgado` todos y solo los préstamos malos.\n",
    "* Pon en una variable `prestamos_seguros` una muestra aleatoria de préstamos buenos **del mismo tamaño** que la cantidad de préstamos malos. (Usa [pandas.DataFrame.sample](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html) con el atributo `random_state=0`)\n",
    "* Junta en una nueva variable `prestamos_balanceados`, los dos grupos anteriores: `prestamos_arriesgados` y `prestamos_seguros`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tus soluciones\n",
    "prestamos_arrriesgado= loans[loans.prestamos_seguros==-1]\n",
    "prestamos_seguros=loans[loans.prestamos_seguros==1].sample(len(prestamos_arrriesgado),random_state=0)\n",
    "prestamos_balanceados= pd.concat([prestamos_arrriesgado,prestamos_seguros])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 . Asigna a una variable `subconjunto_prestamos` sólo el siguiente subconjunto de características que son las que usaremos:\n",
    "\n",
    "```python\n",
    "caracteristica = ['grade',               # grade of the loan\n",
    "            'sub_grade',                 # sub-grade of the loan\n",
    "            'short_emp',                 # one year or less of employment\n",
    "            'emp_length_num',            # number of years of employment\n",
    "            'home_ownership',            # home_ownership status: own, mortgage or rent\n",
    "            'dti',                       # debt to income ratio\n",
    "            'purpose',                   # the purpose of the loan\n",
    "            'term',                      # the term of the loan\n",
    "            'last_delinq_none',          # has borrower had a delinquincy\n",
    "            'last_major_derog_none',     # has borrower had 90 day or worse rating\n",
    "            'revol_util',                # percent of available credit being used\n",
    "            'total_rec_late_fee',        # total late fees received to day\n",
    "           ]\n",
    "```\n",
    "\n",
    "Asimismo, asigna a una variable **`y`** los valores de la columna `prestamos_seguros`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu solucion\n",
    "caracteristica = ['grade',               # grade of the loan\n",
    "            'sub_grade',                 # sub-grade of the loan\n",
    "            'short_emp',                 # one year or less of employment\n",
    "            'emp_length_num',            # number of years of employment\n",
    "            'home_ownership',            # home_ownership status: own, mortgage or rent\n",
    "            'dti',                       # debt to income ratio\n",
    "            'purpose',                   # the purpose of the loan\n",
    "            'term',                      # the term of the loan\n",
    "            'last_delinq_none',          # has borrower had a delinquincy\n",
    "            'last_major_derog_none',     # has borrower had 90 day or worse rating\n",
    "            'revol_util',                # percent of available credit being used\n",
    "            'total_rec_late_fee',        # total late fees received to day\n",
    "           ]\n",
    "subconjunto_prestamos=loans[caracteristica]\n",
    "y= loans['prestamos_seguros']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 .  Usando [pandas.get_dummies](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) convierte las variables categóricas de `subconjunto_prestamos` en variables numéricas *one-hot*. Guarda el nuevo conjunto de datos en `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu solucion\n",
    "X=pd.get_dummies(subconjunto_prestamos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 .  Empleando `sklearn.model_selection.train_test_split` separa el conjunto de datos en un 90% para entrenamiento y validación (`X_entrenamiento_val`, `y_entrenamiento_val`), y 10% para pruebas (`X_prueba`, `y_prueba`).\n",
    "\n",
    "Luego separa (`X_entrenamiento_val`, `y_entrenamiento_val`) en un 80% para entrenamiento (`X_entrenamiento`, `y_entrenamiento`) y 20% para validación (`X_val`, `y_val`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu solucion\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_entrenamiento_val, X_prueba, y_entrenamiento_val, y_prueba =train_test_split(X, y, test_size=0.10)\n",
    "\n",
    "X_entrenamiento, X_val, y_entrenamiento, y_val =train_test_split(X_entrenamiento_val, y_entrenamiento_val, test_size=0.20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 . Entrena un modelo como Regresión Logística, Naive Bayes, KNN y un cuarto modelo de tu elección, con las siguientes indicaciones:\n",
    "\n",
    "* Utilizar el uso apropiado de la normalización (Scaling) de datos si fuese necesario.\n",
    "* El uso apropiado de una técnica para la selección de los mejores parámetros de cada modelo (p.ej. búsqueda grid o búsqueda aleatoria)\n",
    "* Reporte para cada modelo la exactitud , precisión y exhaustividad, F1-Score  **en el conjunto de pruebas.** y muestra la matriz de confusión.\n",
    "* Comenta tus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Regresion logistica\n",
      "Exactitud: 0.819\n",
      "Precision: 0.822\n",
      "F1-score: 0.819\n",
      "Matriz de confusion:\n",
      "\t-1\t1\n",
      "-1\t 107 \t 2145\n",
      "1\t 78 \t 9931\n",
      "--------------------------------------------------------------------\n",
      "Naive bayes\n",
      "Exactitud: 0.737\n",
      "Precision: 0.854\n",
      "F1-score: 0.737\n",
      "Matriz de confusion:\n",
      "\t-1\t1\n",
      "-1\t 857 \t 1395\n",
      "1\t 1833 \t 8176\n",
      "--------------------------------------------------------------------\n",
      "Vecinos cercados\n",
      "Exactitud: 0.816\n",
      "Precision: 0.824\n",
      "F1-score: 0.816\n",
      "Matriz de confusion:\n",
      "\t-1\t1\n",
      "-1\t 146 \t 2106\n",
      "1\t 145 \t 9864\n",
      "--------------------------------------------------------------------\n",
      "Arbol de decision\n",
      "Exactitud: 0.819\n",
      "Precision: 0.820\n",
      "F1-score: 0.819\n",
      "Matriz de confusion:\n",
      "\t-1\t1\n",
      "-1\t 70 \t 2182\n",
      "1\t 36 \t 9973\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Tus soluciones\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import neighbors\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#primer modelo\n",
    "logistic = linear_model.LogisticRegression()\n",
    "logistic.fit(X_entrenamiento,y_entrenamiento)\n",
    "\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "print(\"Regresion logistica\")\n",
    "print(\"Exactitud: %3.3f\" %accuracy_score(y_prueba,logistic.predict(X_prueba)))\n",
    "print(\"Precision: %3.3f\" %precision_score(y_prueba,logistic.predict(X_prueba)))\n",
    "print(\"F1-score: %3.3f\" %f1_score(y_prueba,logistic.predict(X_prueba),average='micro'))\n",
    "\n",
    "cm = confusion_matrix(y_pred=logistic.predict(X_prueba),y_true=y_prueba)\n",
    "print(\"Matriz de confusion:\")\n",
    "print(\"\\t\"+str(logistic.classes_[0])+\"\\t\"+str(logistic.classes_[1]))\n",
    "print(str(logistic.classes_[0]) + \"\\t\",cm[0][0],\"\\t\",cm[0][1])\n",
    "print(str(logistic.classes_[1]) + \"\\t\",cm[1][0],\"\\t\",cm[1][1])\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "#segundo modelo\n",
    "nb = naive_bayes.GaussianNB();\n",
    "nb.fit(X_entrenamiento,y_entrenamiento);\n",
    "print(\"Naive bayes\")\n",
    "print(\"Exactitud: %3.3f\" %accuracy_score(y_prueba,nb.predict(X_prueba)))\n",
    "print(\"Precision: %3.3f\" %precision_score(y_prueba,nb.predict(X_prueba)))\n",
    "print(\"F1-score: %3.3f\" %f1_score(y_prueba,nb.predict(X_prueba),average='micro'))\n",
    "\n",
    "cm = confusion_matrix(y_pred=nb.predict(X_prueba),y_true=y_prueba)\n",
    "print(\"Matriz de confusion:\")\n",
    "print(\"\\t\"+str(nb.classes_[0])+\"\\t\"+str(nb.classes_[1]))\n",
    "print(str(nb.classes_[0]) + \"\\t\",cm[0][0],\"\\t\",cm[0][1])\n",
    "print(str(nb.classes_[1]) + \"\\t\",cm[1][0],\"\\t\",cm[1][1])\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "\n",
    "#tercer modelo\n",
    "knn = neighbors.KNeighborsClassifier(20, weights='distance')\n",
    "knn.fit(X_entrenamiento, y_entrenamiento)\n",
    "print(\"Vecinos cercados\")\n",
    "print(\"Exactitud: %3.3f\" %accuracy_score(y_prueba,knn.predict(X_prueba)))\n",
    "print(\"Precision: %3.3f\" %precision_score(y_prueba,knn.predict(X_prueba)))\n",
    "print(\"F1-score: %3.3f\" %f1_score(y_prueba,knn.predict(X_prueba),average='micro'))\n",
    "\n",
    "cm = confusion_matrix(y_pred=knn.predict(X_prueba),y_true=y_prueba)\n",
    "print(\"Matriz de confusion:\")\n",
    "print(\"\\t\"+str(nb.classes_[0])+\"\\t\"+str(nb.classes_[1]))\n",
    "print(str(nb.classes_[0]) + \"\\t\",cm[0][0],\"\\t\",cm[0][1])\n",
    "print(str(nb.classes_[1]) + \"\\t\",cm[1][0],\"\\t\",cm[1][1])\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "\n",
    "#cuarto modelo\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "parameters = {'max_depth':[5, 10, 15, 20, 25, 32]}\n",
    "decision_tree_gs = GridSearchCV(decision_tree, parameters, cv=5)\n",
    "decision_tree_gs.fit(X_entrenamiento, y_entrenamiento)\n",
    "print(\"Arbol de decision\")\n",
    "print(\"Exactitud: %3.3f\" %accuracy_score(y_prueba,decision_tree_gs.predict(X_prueba)))\n",
    "print(\"Precision: %3.3f\" %precision_score(y_prueba,decision_tree_gs.predict(X_prueba)))\n",
    "print(\"F1-score: %3.3f\" %f1_score(y_prueba,decision_tree_gs.predict(X_prueba),average='micro'))\n",
    "\n",
    "cm = confusion_matrix(y_pred=decision_tree_gs.predict(X_prueba),y_true=y_prueba)\n",
    "print(\"Matriz de confusion:\")\n",
    "print(\"\\t\"+str(nb.classes_[0])+\"\\t\"+str(nb.classes_[1]))\n",
    "print(str(nb.classes_[0]) + \"\\t\",cm[0][0],\"\\t\",cm[0][1])\n",
    "print(str(nb.classes_[1]) + \"\\t\",cm[1][0],\"\\t\",cm[1][1])\n",
    "print(\"--------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
